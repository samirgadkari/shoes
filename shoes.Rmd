---
title: "Analyze Shoes Data"
author: "Samir Gadkari"
date: "2/20/2021"
output: html_document
---

Data Source: [Shoes dataset](https://datafiniti.co)

```{r}
library(tidyverse)
library(lubridate)
library(modelr)
library(RcppRoll)
library(ggpubr)
library(splines)
```

# 1. Import data
```{r}
shoes <- read_csv("../mens_shoe_prices.csv")
```
There are 29 parsing problems. Let's see if the rest of our data
looks good.

```{r}
nrow(shoes)
ncol(shoes)
head(shoes)
```

We have a lot of rows (other than the 29 parsing failures).
Let's continue with what we have.

# 2. Analyze
## 2.1 Select columns and rows

Let's look at which columns have many NA values.
Then we can decide which ones to use.
```{r}
fraction_not_missing <- function(x) {
  mean(!is.na(x))
}

x <- sort(unlist(map(shoes, fraction_not_missing)), 
          decreasing = TRUE)

# Putting the values in a dataframe just makes it easier to read
df <- tibble(name = names(x), values = as.vector(x))
knitr::kable(df)
```

Some things to note about this dataframe:

  * There are many other items than shoes.
  * The id is not unique - we may not use it, but it's good to note this
  * categories contain values from the features column's JSON string
  * dateadded, dateupdated: We will need these if we're looking at timelines.
                            Are there many rows with different values between these
                            columns?
  * keys: contain the brand name / manufacturer number. These have already been parsed
          into brand and manufacturernumber columns.
          The brand column is almost fully populated.
          78% of the manufacturernumber column is populated
  * name: What you would expect to see as the name of the shoe
  * prices_amountmax
  * prices_amountmin
  * prices_dateadded
  * prices_dateseen: What is the difference between prices_dateadded and prices_dateseen?
  * prices_issale
  * prices_currency: What are all the currencies in this dataset? 
                     If only one currency, we can ignore this column.
  * prices_sourceurls: Contains the Website and merchant names.
                       This has been extracted into the prices_merchant column,
                       so we can drop this column.
  * sourceurls: Looks the same as prices_sourceurls. Drop it.
  * brand: We can use this to compare prices by brand
  * imageurls: We don't need this. Even if we did, there is no guarantee that
               the images exist anymore on the website. Drop it.
  * manufacturernumber: We can use this to see what price range different manufacturers 
                        target
  * merchants: Contains "dateSeen" and "name"
  * features: Provides color, dimensions, etc.
  * prices_merchant: Contains seller name and website where product is sold
  
### 2.1.1 Get columns with only mens shoes

Here we decided not to get sandals, slippers, or crocs since they're
not shoes. 

We tried using the categories column, but it labeled
"Mens Shoes" for sandals, infant shoes, and shoe studs.
You can check the names column
```{r}
head((shoes %>% 
  filter(str_detect(categories, "[Mm]en")) %>%
  filter(str_detect(categories, "[Ss]hoe")))["name"], n = 15)
```

This is more precise:

```{r}
mens_shoes <- shoes %>%
  filter(str_detect(name, "[Mm]en"))
mens_shoes <- mens_shoes %>%
  filter(str_detect(name, "[Ss]hoe") | 
         str_detect(name, "[Bb]oot") |
         str_detect(name, "[Ll]oafer") | 
         str_detect(name, "[Ss]tep") |
         str_detect(name, "[Ss]neaker") | 
         str_detect(name, "[Tt]rainer") |
         str_detect(name, "[Oo]xford") | 
         str_detect(name, "[Cc]anvas"))
nrow(mens_shoes)/nrow(shoes)
head(mens_shoes["name"], n = 15)
```

That gives us a much smaller dataframe - it contains only 34% 
of the original number of rows.

### 2.1.2 Are dateadded, dateupdated, and prices_dateseen different?

```{r}
dateadded <- mens_shoes$dateadded
dateupdated <- mens_shoes$dateupdated
prices_dateseen <- mens_shoes$prices_dateseen
typeof(dateadded)
typeof(dateupdated)
typeof(prices_dateseen) # This is a character vector -  convert it.
prices_dateseen <- ymd_hms(prices_dateseen)

mean(!(dateadded == dateupdated), na.rm = TRUE)
mean(!(dateupdated == prices_dateseen), na.rm = TRUE)
mean(!(prices_dateseen == dateadded), na.rm = TRUE)
```

So we see that dateadded and dateupdated are different 1/3 of the time.
dateupdated and prices_dateseen are 98% different.
prices_dateseen and dateadded are 94% different.

Let's see if they're different by more than a day:
```{r}
mean(abs(dateadded - dateupdated) > days(1), na.rm = TRUE)
mean(abs(dateupdated - prices_dateseen) > days(1), na.rm = TRUE)
mean(abs(prices_dateseen - dateadded) > days(1), na.rm = TRUE)
```

This output is similar to the output earlier with:

  * 31% difference of more than a day between dateadded and dateupdated
  * 87% difference of more than a day between dateupdated and 
    prices_dateseen
  * 84% difference of more than a day between prices_dateseen and
    dateadded

This means there is information in these dates that might be useful.
According to the schema, dateadded was the date when the original
item was added. dateupdated was the date of the last product update.
prices_dateseen was the date that the given price was last seen.

### 1.2.3 Can we restrict ourselves to just one currency?

```{r}
mens_shoes %>% count(prices_currency, sort = TRUE)
```

Looks like USD is mostly use - let's remove all other rows and
the currency column.

```{r}
nrow(mens_shoes)
mens_shoes <- mens_shoes %>% 
  filter(prices_currency == "USD") %>%
  select(-prices_currency)
nrow(mens_shoes)
```

That makes sense - we lost around 170 rows. This is around what
we see when we sum up the frequencies of non-USD currencies above.

### 1.2.4 Drop all columns we don't need


```{r}
ncol(mens_shoes)
mens_shoes <- mens_shoes %>%
  select(-colors, -upc, -ean, -descriptions,
         -skus, -manufacturer, -prices_offer, -sizes,
         -prices_shipping, -dimension, -asins, -reviews,
         -prices_returnpolicy, -weight, -prices_color,
         -prices_size, -prices_availability, -prices_warranty,
         -prices_count, -prices_flavor, -vin, -quantities,
         -websiteids, -count, -flavors, -isbn, -prices_source,
         -prices_sourceurls, -sourceurls, -imageurls)
ncol(mens_shoes)
```

### 1.2.5 Convert prices_amountmin and prices_amountmax to numeric
```{r}
mens_shoes$prices_amountmax <- as.double(mens_shoes$prices_amountmax)
mens_shoes$prices_amountmin <- as.double(mens_shoes$prices_amountmin)

typeof(mens_shoes$prices_amountmax)
typeof(mens_shoes$prices_amountmin)
```

# 2. Analyse dataset

## 2.1 Which brands are cheapest/costliest?

How many brands are there?
```{r}
brands <- mens_shoes %>%
  count(brand, sort = TRUE)

nrow(brands)
brands
```

There are 643 brands. Most of the data are prices for the larger
brands (Nike, PUMA, VANS, New Balance, Reebok, Jordan, SKECHERS,
and adidas).

Let's look at how the prices_amountmin and prices_amountmax stack up:
```{r}
min(mens_shoes$prices_amountmin)
max(mens_shoes$prices_amountmin)
mens_shoes %>%
  select(prices_amountmax, prices_amountmin) %>%
  ggplot(aes(prices_amountmin, prices_amountmax)) +
  geom_point(alpha = 1 / 10) +
  scale_x_continuous(name = "minimum prices", 
                     breaks = seq(0, 1500, 300)) +
  scale_y_continuous(name = "maximum prices", 
                     breaks = seq(0, 1500, 300))
```

Prices larger than 300 dont change. Let's see how many prices have a
different minimum and maximum price:
```{r}
mean(mens_shoes$prices_amountmax > mens_shoes$prices_amountmin)
```

So only around 4.5% of the dataset contain items whose 
minimum and maximum prices are different. Most of the
items are at the same price. We should look into these
items, as they are not price elastic. This means
that the manufacturer/distributor can increase price,
and the demand for it will not decrease much. Thus the
company will make more money.

Let's continue with comparing prices by brand.
We have to make sure the condition of the product is good.
We will only consider products in the "new" condition
```{r}
mean(!is.na(mens_shoes$prices_condition))
unique(mens_shoes$prices_condition)
```

Look at the top 10 largest minimum price brands:
```{r}
costliest_brands <- mens_shoes %>%
  select(brand, prices_condition, prices_amountmin) %>%
  filter(prices_condition %in% c("New", "new")) %>%
  arrange(desc(prices_amountmin)) %>%
  select(-prices_condition)

costliest_brands <- unique(head(costliest_brands["brand"], n = 15))
costliest_brands
```

Look at the top 10 smallest maximum price brands:

```{r}
cheapest_brands <- mens_shoes %>%
  select(brand, prices_condition, prices_amountmax) %>%
  filter(prices_condition %in% c("New", "new")) %>%
  arrange(prices_amountmax) %>%
  select(-prices_condition)

unique(head(cheapest_brands["brand"], n = 13))
```

We will assume that MuckBoot and Muck Boots are the same brand.
There is a "The Original Muck Boot Company". We will replace the
"Muck Boots" brand with "MuckBoot" brand name.

```{r}
cheapest_brands$brand <- str_replace_all(cheapest_brands$brand, 
                                         "Muck Boots", "MuckBoot")
cheapest_brands <- unique(head(cheapest_brands["brand"], n = 13))
```

Now we can plot the prices for the cheapest and costliest brands:

```{r}
top_bottom_brands <- as.vector(rbind(costliest_brands["brand"],
                               cheapest_brands["brand"]))
top_bottom_brands <- as.vector(unlist(top_bottom_brands))
top_bottom_brands
```

Now let's filter our original data for just these brands:

```{r}
top_bottom_brands_data <- mens_shoes %>%
  filter(brand %in% top_bottom_brands) %>%
  select(brand, prices_amountmin, prices_amountmax)

top_brands <- top_bottom_brands_data %>%
  select(brand, prices_amountmin) %>%
  rename(price = prices_amountmin)
top_brands

bottom_brands <- top_bottom_brands_data %>%
  select(brand, prices_amountmax) %>%
  rename(price = prices_amountmax)
bottom_brands

top_bottom_brands_data <- rbind(top_brands, bottom_brands)
top_bottom_brands_data
```

We will now graph the results:
```{r}
top_bottom_brands_data %>%
  ggplot(aes(brand, price)) +
  geom_boxplot() +
  coord_flip()
```

### 2.1.1 Save for for Shiny App

```{r}
write_csv(top_bottom_brands_data, 
          "processed/top_bottom_brands.csv")
```

## 2.2 Which type of shoe is cheapest/costliest?

```{r}
shoe_type <- function(x) {
  case_when(
    str_detect(x, "[Ss]hoe") ~ "Shoe",
    str_detect(x, "[Bb]oot") ~ "Boot",
    str_detect(x, "[Ll]oafer") ~ "Loafer",
    str_detect(x, "[Ss]tep") ~ "Step",
    str_detect(x, "[Ss]neaker") ~ "Sneaker",
    str_detect(x, "[Tt]rainer") ~ "Trainer",
    str_detect(x, "[Oo]xford") ~ "Oxford",
    str_detect(x, "[Cc]anvas") ~ "Canvas",
    TRUE ~ NA_character_
  )
}

mens_shoes %>%
  mutate(shoe_type = shoe_type(name)) %>%
  group_by(shoe_type) %>%
  ggplot(aes(x = (prices_amountmax + prices_amountmin) / 2,
             y = shoe_type,
             color = shoe_type)) +
  geom_boxplot() +
  labs(x = "Average price", y = "Shoe type")
```

It is the boot that is the costliest, 
and the canvas is the cheapest.

### 2.2.1 Save file for Shiny App

```{r}
mens_shoe_prices_by_type <- mens_shoes %>%
  mutate(
    shoe_type = shoe_type(name),
    avg_price = (prices_amountmax + prices_amountmin) / 2
  ) %>%
  select(dateupdated, shoe_type, avg_price)

write_csv(mens_shoe_prices_by_type, 
          "processed/mens_shoe_prices_by_type.csv")
```

## 2.3 Inelastic shoes prices

If the prices of shoes are inelastic, then the manufacturer
can increase the price without demand for it dropping.

We cannot tell from this dataset if the price was increased or decreased.
The schema does say that prices for this product are given as a list
with the dateSeen value showing the date that particular price
was seen. Unfortunately, the processed dataset that came with the schema
shows only that the price changed on a particular date, but not if it was 
increased or decreased.

If I were working on this dataset, I would ask for that data.
We cannot proceed anymore along this line of inquiry.

## 2.4 The timeline of price changes

### 2.4.1 When are prices changed?

```{r}
# We're using Meteorological seasons, since we want to
# see if our data has any relation to the weather.
season <- function(date) {
  case_when(
    month(date) >= 3 && month(date) <= 5 ~ "Spring",
    month(date) >= 6 && month(date) <= 8 ~ "Summer",
    month(date) >= 9 && month(date) <= 11 ~ "Fall",
    month(date) == 12 || month(date) >= 1 ~ "Winter"
  )
}

mens_shoes_summary <- mens_shoes %>%
  filter(dateadded != dateupdated) %>%
  group_by(dateupdated) %>%
  summarise(
    dateupdated = dateupdated,
    n = n()
  ) %>%
  mutate(season = season(dateupdated))

mens_shoes_summary$rolling_mean <- roll_meanr(mens_shoes_summary$n, n = 60L)

dates <- c(ymd(20160726), ymd(20160915))
dates <- as_datetime(dates)

mens_shoes_summary %>%
  ggplot(aes(dateupdated, rolling_mean, color = season)) +
  geom_path(aes(group = 1), size = 1, na.rm = TRUE) +
  annotate(geom = "vline",
          x = dates,
          xintercept = dates,
          linetype = "dashed",
          color = "black") +
  annotate(geom = "text",
           x = dates - ddays(8),
           label = as.character(dates),
           y = 50,
           angle = 90) +
  xlab("date updated") +
  ylab("rolling mean")
```

Most of the price changes occur starting the end of July and ending
mid September. There are also smaller bumps which may be because
of seasonal changes. There is a bump around May, and another
around Jan/Feb 2017. There is no bump around Jan/Feb 2016 because
that's when the data started, so the prices were not updated yet.

### 2.4.2 Model the price changes

Let's remove the columns we don't need:
```{r}
mens_shoes_summary <- mens_shoes_summary %>%
  filter(!is.na(rolling_mean))
mens_shoes_summary$season <- as.factor(mens_shoes_summary$season)
mens_shoes_summary <- mens_shoes_summary %>% select(-n)
```

Also, for future we will need to create and test many models.
Let's create functions that will let us do that:
```{r}
apply_model_and_plot <- function(model, data, labels) {
  plot_pred <- data %>%
    add_predictions(model) %>%
    ggplot(aes(dateupdated, pred)) +
    geom_line(na.rm = TRUE)

  plot_resid <- data %>%
    add_residuals(model) %>%
    ggplot(aes(dateupdated, resid)) +
    geom_line(na.rm = TRUE)
  
  ggarrange(plot_pred, plot_resid, 
            labels = labels,
            hjust = -0.1,
            nrow = 2, ncol = 1)
}
```

If we model the price changes, we may be able to predict future
years prices. We don't have the data for that, but we will go
through this exercise for the one year we have.

```{r}
mod_rolling_mean <- lm(rolling_mean ~ dateupdated * season,
                       data = mens_shoes_summary)
apply_model_and_plot(mod_rolling_mean, mens_shoes_summary,
                     c("Interaction model predictions", 
                       "Interaction model residuals"))
broom::glance(mod_rolling_mean)
```

You can see that a simple linear model is not going to model
this data well:

Let's try splines:
```{r}
# mod_rolling_mean <- 
#   MASS::rlm(rolling_mean ~ ns(dateupdated, 5) * season,
#             data = mens_shoes_summary)
# apply_model_and_plot(mod_rolling_mean, mens_shoes_summary,
#                      c("Spline model predictions", 
#                        "Spline model residuals"))
# broom::glance(mod_rolling_mean)
```

With splines, we get an error:
"'x' is singular: singular fits are not implemented in 'rlm'".
I have the season factor, but it is all populated:
```{r}
sum(mens_shoes_summary %>% 
  group_by(season) %>%
  summarise(n = n()) %>%
  select(n))

nrow(mens_shoes_summary)
```

This is probably happening because there are duplicate rows.
Let's try to remove them and then do a fit:
```{r}
unique_rows <- unique(mens_shoes_summary)
# mod_rolling_mean <- 
#   MASS::rlm(rolling_mean ~ ns(dateupdated, 5) * season,
#             data = unique_rows)
# apply_model_and_plot(mod_rolling_mean, unique_rows,
#                      c("Spline model predictions", 
#                      "Spline model residuals"))
# broom::glance(mod_rolling_mean)
```

This still gives the same error. Let's put this aside for now.

# 2.5 Save processed file to disk

We will use the processed file for our Shiny app.
We have to make sure there is not much processing required
on the app server. If we do, it will slow down the user interface.

Shiny apps on shinyapp.io also require the data files to be
inside the directory of subdirectory where the main app resides.
```{r}
write_csv(mens_shoes_summary, "processed/mens_shoes_summary.csv")
```

# 2.6 Mens shoe price changes (per shoe type)

```{r}
head(mens_shoes)
head(mens_shoes_summary)

mens_shoes_with_type <- mens_shoes %>%
  filter(dateadded != dateupdated) %>%
  group_by(dateupdated) %>%
  mutate(
    dateupdated = dateupdated,
    shoe_type = shoe_type(name),
    season = season(dateupdated)
  ) %>%
  summarise(
    dateupdated = dateupdated,
    shoe_type = shoe_type(shoe_type),
    season = season(dateupdated),
    n = n()
  )

unique(mens_shoes_with_type %>% 
  group_by(shoe_type) %>%
  summarise(
    shoe_type = shoe_type,
    n = n()
  )
)
```

There are too many prices to see. The number of Step and Trainer
price changes are really small to count. Let's remove them.

```{r}
mens_shoes_with_type <- mens_shoes_with_type %>%
  filter(shoe_type != "Step" & shoe_type != "Trainer")

mens_shoes_with_type %>%
  ggplot(aes(dateupdated, n, color = shoe_type)) +
  geom_point() +
  labs(x = "Date updated", y = "Count")
```

### 2.6.1 Save mens shoes with type to disk

```{r}
write_csv(mens_shoes_with_type, "processed/mens_shoes_with_type.csv")
```
